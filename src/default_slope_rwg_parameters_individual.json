{
    "general": {
        "learning_type": "centralised",
        "algorithm_selected": "rwg",
        "team_type": "heterogeneous",
        "reward_level": "individual",
        "agent_type": "nn",
        "environment": "slope",
        "calculate_specialisation": "True",
        "seed": 1,
        "using_novelty": "False"
    },
    "environment": {
        "slope": {
            "num_agents": 1,
            "num_resources": 16,
            "sensor_range": 1,
            "sliding_speed": 8,
            "arena_length": 8,
            "arena_width": 16,
            "cache_start": 1,
            "slope_start": 3,
            "source_start": 7,
            "base_cost": 1,
            "upward_cost_factor": 3.0,
            "downward_cost_factor": 0.2,
            "carry_factor": 2,
            "resource_reward": 1000,
            "episode_length": 100,
            "num_episodes": 5,
            "incremental_rewards": "False",
            "env_seed": 1,
            "bc_measure": "avg_pos"
        }
    },
    "agent": {
        "nn": {
            "architecture": "rnn",
            "bias": "False",
            "hidden_layers": 1,
            "hidden_units_per_layer": 4,
            "activation_function": "tanh"
        }
    },
    "algorithm": {
        "agent_population_size": 10000,
        "rwg": {
            "sampling_distribution": "normal",
            "normal": {
                "mean": 0,
                "std": 1
            },
            "uniform": {
                "min": -3,
                "max": 3
            },
            "lhs": {
                "min": -6,
                "max": 6
            }
        },
        "cma": {
            "sigma": 0.2,
            "generations": 1000,
            "tolx": 0.001,
            "tolfunhist": 200.0,
            "logging_rate": 50,
            "seeding_required": "True"
        }
    }
}