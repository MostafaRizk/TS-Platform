\documentclass[12pt]{article}
\usepackage{graphicx}
\graphicspath{ {./figures/} }

\makeatletter
\def\thickhline{%
  \noalign{\ifnum0=`}\fi\hrule \@height \thickarrayrulewidth \futurelet
   \reserved@a\@xthickhline}
\def\@xthickhline{\ifx\reserved@a\thickhline
               \vskip\doublerulesep
               \vskip-\thickarrayrulewidth
             \fi
      \ifnum0=`{\fi}}
\makeatother

\newlength{\thickarrayrulewidth}
\setlength{\thickarrayrulewidth}{4\arrayrulewidth}

\title{Final Report:\\ Neuroevolution of Task Specialisaiton for Multi-Agent Systems}
\author{Mostafa Rizk}

\setlength{\parindent}{0pt}

\begin{document}

\maketitle

\section{Introduction}

\section{Landscape Analysis}

\textbf{What are the fundamental features of the fitness landscape of a task specialisation problem?}\\

\subsection{Creating a Fitness Gradient}

One conclusion of the research so far has been that the landscape of task specialisation problems appears to be very flat and thus difficult to find any solution at all, let alone a specialised one.
If a flat fitness landscape is inherent to task specialisation problems, then this is significant because it implies that algorithms that are highly exploratory should be used, as they are with similar problems \cite{oller:AAMAS:2020}.
However, it is also possible that the fitness function might be making evolution unnecessarily difficult because it only rewards task completion, treating partial success the same as failure.
If partial successes are rewarded, the landscape could have a smoother gradient, making it easier for evolution to traverse.
This leads to the following hypothesis:\\

\textbf{Hypothesis 1.1:} Rewarding agents for partial retrieval of the resource will create a smoother fitness gradient.\\

This hypothesis is answered by conducting the following experiment:\\

\textbf{Experiment 1.1- RWG Analysis with Modified Fitness:}  Modify the fitness function such that agents are rewarded for partially retrieving a resource.
Specifically, divide the reward for retrieving a resource by the length of the arena and give agents part of the reward if they move the resource a single tile closer to the goal.
Then conduct RWG analysis as described in \cite{oller:AAMAS:2020} and compare the plots to those produced for the original fitness function.\\

If the mean curve of the distribution has a smoother gradient, then the hypothesis is supported.\\

The plots for the original landscape analysis and the analysis with the new fitness function are shown in Figure \ref{fig:sparse} and Figure \ref{fig:incremental} respectively.\\

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{sparse_rewards.png}
\caption{RWG Analysis with the original fitness function}
\label{fig:sparse}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{incremental_rewards.png}
\caption{RWG Analysis with incremental rewards}
\label{fig:incremental}
\end{figure}

Looking at the 6 mean plots in Figure \ref{fig:incremental} compared to Figure \ref{fig:sparse}, we see that with incremental rewards, the solutions do in fact form more of a gradient towards the right end of the plot, in particular for RNNs (bottom row). 
This means that a lot of the solutions in the landscape are partially successful at retrieving resources. 
However, the landscape is still largely flat. 
This is presumably because most solutions in the landscape don't even get to the point of picking up a resource from the source.\\ 

Thus the answer to Hypothesis 1.1 is:\\

\textbf{Answer 1.1:} Rewarding agents for partial retrieval of the resource creates a smoother fitness gradient, but the landscape is still largely flat.\\

In order to further smooth the fitness landscape there would need to be rewards for partial progress up the slope, but the problem with this is that it is likely to disincentivise the collector behaviour in evolution.
Why would an agent stay at the nest and collect resource when they are rewarded for going up the slope? 
Additionally, while this problem is simple enough to smooth the fitness gradient in this way, such smoothing may not be possible for other more complex problems.
The purpose of this research is to understand how to use AI to find good solutions with minimal (if any) human intervention.\\

Moreover, the flatness of the landscape is, to some extent, inherent to this task.
This is a problem common in evolutionary computation known as the bootstrapping problem \cite{Silva:EC:2016, Wei:ALR:2019}.
Bootstrapping is "when the task is too demanding for the fitness function to apply any meaningful selection pressure on a randomly generated population of initial candidate solutions" \cite{Silva:EC:2016}.
The bootstrapping problem often occurs when the goal behaviour is complex relative to the very simple available actions \cite{Wei:ALR:2019}.
For this problem, the available actions are primitives like 'move forward one tile' and 'move backward one tile'.
When putting together sequences of these actions, most sequences will obviously not be very successful.\\

There are many proposed solutions to solving the bootstrapping problem and they fall under the broad categories of inserting human knowledge into the learning process or increasing the diversity of solutions \cite{Silva:EC:2016}.
Smoothing the landscape falls under the former category, but this family of techniques has some shortcomings, in particular it reduces the potential for automation and risks the experimenter introducing negative biases.
Using rwg to find a seed falls under the second category; it has the shortcoming of additional computation, which may not scale well for problems with larger solution spaces, but for those problems there is a wealth of alternative techniques for increasing diversity, such as novelty search.
In keeping with the spirit of AI, I have chosen to continue using the more challenging fitness function.

\subsection{Visualising Specialisation}

I already performed the initial analysis of the landscape (Figure \ref{fig:sparse}), however, the visualisation did not contain any information about how specialised each team was i.e. was a given solution a pair of generalists or a pair of specialists? 
Are the better solutions in the landscape usually specialists? 
To visualise this information I need a way of measuring the degree of specialisation of a solution, so the second task in this group is to evaluate some candidate metrics and the third is to incorporate the chosen metric into the landscape analysis.
The hypothesis and experiment are:\\

\textbf{Hypothesis 1.2:} Specialist solutions outperform generalist ones.\\

\textbf{Experiment 1.2- Specialisation Plots of RWG Analysis:}  Use the chosen specialisation metric to assess all the solutions found by RWG analysis and incorporate them into the plots.\\

The most specialised solutions are expected to be at the rightmost of the mean plot and above the generalist ones.
If this is the case, then it supports the hypothesis.
If there are generalist solutions that outperform specialist ones, it disproves the hypothesis.

\subsubsection{Specialisation in the Literature}

To quantitatively measure specialisation, it is important to first define what specialisation is.
For the purpose of this research, specialisation is when a team of agents cooperate, by performing different roles, to accomplish the task more effectively than a team of generalist (i.e. independent) agents.
Agents cooperating by doing the same role, e.g. carrying a resource together, is not considered specialisation.
Agents performing different roles that do not provide an advantage over a generalist team (e.g. one agent doing a generalist strategy and another agent being stationary) is also not considered specialisation.\\

This research is only concerned with tasks where specialisation improves performance and how to effectively evolve specialisation for those tasks.
In real-world applications, we may not know a priori what the specialist solution to the problem is, but for the slope foraging problem, we know that it involves a subset of agents dropping resources from the top of the slope and the rest of the agents collecting the dropped resources from the cache.
Therefore, our metric must be one that indicates these dropper and collector behaviours are being enacted to retrieve resources.\\

The way specialisation is measured in the literature uses one or more of the following:\\

\textbf{Strategy switches}\\

Nitschke et al \cite{nitschke:SEC:2012} count times strategy was switched over all possible switches. Less switches means more specialised.
Gautrais et al \cite{gautrais:JTB:2002} do the same but take the complement.
Gigliotta  et al \cite{gigliotta:Neurocomputing:2018} counts time spent changing strategies.
Pini et al \cite{pini:SI:2011, pini:ICSI:2012} use an analog of Ferrante et al's slope foraging \cite{ferrante:PLoSCB:2015}, where there is a source and a nest and agents can either take a long corridor to the nest or place items in a cache that transports them to the other side, where their team-mates take them to the nest.
They count the number of times the cache was chosen instead of the corridor as an indicator of the degree of specialisation.\\

These are not easily applicable to this slope foraging implementation because it uses low-level actions, whereas they assume agents can directly choose a high-level strategy. 
Agents changing from "go forward" to "go backward" doesn't tell much about specialisation. But if agent actions were just "do dropper behaviour", "do collector behaviour" and "do generalist behaviour", it would be more feasible to use measures like these works. Some measures also look at specialisation of the individual rather than the team, which is not as meaningful for slope foraging.\\

\textbf{Diversity and Entropy}\\

Li et al \cite{li:AB:2004} group agent genotypes into clusters and use Shannon's entropy to measure the diversity of the team. Each cluster is believed to be a specialist strategy. Specialisation is defined as "the part of diversity that is demanded for better performance" so a diverse team is only specialised if their diversity is correlated to improved performance. Li et al  then look at diversity and performance through the learning process and calculate their correlation coefficient as a measure for the degree of specialisation of the final strategy(?)\\

This is computationally expensive because it requires data on team performance throughout all of the learning process and requires integration over all algorithm configurations (?). Additionally, since the authors use a PFSM, genotypic diversity implies phenotypic diversity (?). Using a neural network, different genotypes might still have the same behaviour. Since then, work has been done on diversity-based search algorithms. That literature uses behaviour characterisation to describe the behaviour being done. Agents could be clustered according to this, but diversity does not necessarily indicate specialisation or cooperation. More recent work by Gomes et al \cite{gomes:IEEETR:2017} use co-evolution to evolve heterogeneous cooperative teams, they count the number of different agents or populations. Populations with similar behaviours are merged so all agents on the team are different, but again, this does not necessarily indicate that the team has specialised.  \\

O'Donnell and Jeanne \cite{odonnell:BES:1990} calculate the entropy of an individual agent, specifically the proportions of its time spent doing different activities (i.e. the diversity of resources it gathers). They use it directly as the degree of specialisation. This runs into the same problem as before, where the metric is difficult to apply to slope foraging because agents do not choose high-level strategies. In addition the metric is for individuals and does not apply to this context because agents only gather one type of resource. Balch?\\

\textbf{Resource retrieval}\\

Ferrante et al \cite{ferrante:PLoSCB:2015} have a comparatively simple metric. They count the proportion of resources retrieved cooperatively over the total resources retrieved. This is independent of whether actions are high or low level and doesn't need the full evolutionary history. It is designed for slope foraging so is appropriate, though it has shortcomings.  Cooperative retrieval simply means a resource was picked up by two or more agents before being delivered. An agent could pick up and drop the resource at the source and a generalist could come to collect it and that would count as a specialist strategy. Technically, this is still a dropper-collector strategy, but it does not capture the type of dropper-collector strategy that improves performance.\\

Additionally, it does not account for 'hitch-hikers' i.e. agents doing nothing while the rest of the team retrieves all resources cooperatively. Since the Ferrante setup is homogeneous (i.e. all agents have the same policy), it is unlikely that some would cooperate while others hitch-hike, but since this research considers heterogeneous teams, hitch-hikers are more likely to be encountered, so the specialisation metric should distinguish between teams that have a hitch-hiker and teams that don't. It also can't distinguish teams where a dropper and collector swap roles part-way. This is unlikely to occur, though. In short, the Ferrante metric's main shortcoming is that it does not distinguish \textit{imperfect} specialists.

\subsubsection{Choosing a Metric}

Based on a review of techniques in the literature, the metric used by \cite{ferrante:PLoSCB:2015} is the most appropriate. However, to overcome its shortcomings, I propose to add two new terms to the formula. Ferrante et al measure a term I will refer to as the \textit{cooperation rate} or:\\
%
\[ 
R_{coop} = \frac{N_{coop}}{N_{total}}
\]
where:
\begin{description}
\item[$N_{coop}$] is The number of resources retrieved cooperatively (i.e. picked up by at least 2 agents before being delivered to the nest)
\item[$N_{total}$] is The total number of resources retrieved by the team
\end{description}
%
To account for instances of imperfect specialisation where agents cooperatively retrieve a resource but drop or collect it in the wrong place, I introduce the \textit{efficient cooperation rate}:
%
\[ 
R_{coop}' = \frac{N_{coop}'}{N_{total}}
\]
where:
\begin{description}
\item[$N_{spec}$] is The number of resources retrieved using efficient cooperation (i.e. the resource was dropped on the slope, picked up from the cache and the agents that dropped and picked up were different)
\end{description}
%
To capture the spectrum of specialisation, I take the average of the two terms:
%
\[ 
R_{spec} = \frac{R_{coop} + R_{coop}'}{2}
\]
%
To detect "hitch-hikers", I also introduce the \textit{agent participation}:
%
\[ 
P = \frac{A_{active}}{A_{total}}
\]
where:
\begin{description}
\item[$A_{active}$] is The number of agents that participated in the retrieval of at least one resource
\item[$A_{total}$] is The total number of agents on the team
\end{description}
%
The final measure of degree of specialisation is then:
%
\[ 
S = R_{spec} \times P
\]
%
One shortcoming of this metric is that it does not detect role-switching. For example, a team composed of a dropper and a collector but halfway through, the dropper becomes the collector and vice versa. Role-switching can be detected by observing the variance of an agent's y-coordinate in the arena. A dropper or collector that remains in their role throughout runtime will move at most 1 tile in either y direction, so they will have a low variance. An dropper that changes roles will have a high variance, akin to a generalist. The average y-variance of a team indicates role-switching and, to an extent, specialisation. The average variance could potentially be used to measure specialisation on its own, though it would not detect hitch-hikers or even just teams that are completely stationary. For this reason, and to avoid over-complicating the metric, I only use the variance as an additional measure to check for role-switching.

\subsubsection{Results}

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Team Strategy} & \boldmath${R_{coop}}$ & \boldmath$R_{coop}'$ & \boldmath$R_{spec}$\\
\thickhline
Dropper + Collector & 1.0 & 1.0 & 1.0 \\
\hline
Generalist + Generalist & 0.0 & 0.0 & 0.0 \\
\hline
Inefficient Dropper + Collector & & & \\
\hline
Dropper + Collector + Hitch-hiker & & & \\
\hline
Swapper + Swapper & & & \\
\hline
Lazy Generalist + Lazy Generalist & & & \\
\hline
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Team Strategy} & \boldmath${R_{coop}} \times P$ & \boldmath$R_{coop}' \times P$ & \boldmath$R_{spec} \times P$\\
\thickhline
Dropper + Collector & 1.0 & 1.0 & 1.0 \\
\hline
Generalist + Generalist & 0.0 & 0.0 & 0.0 \\
\hline
Inefficient Dropper + Collector & & & \\
\hline
Dropper + Collector + Hitch-hiker & & & \\
\hline
Swapper + Swapper & & & \\
\hline
Lazy Generalist + Lazy Generalist & & & \\
\hline
\end{tabular}
\end{center}

\subsection{Dimensionality Reduction}

The neural networks used to solve the Slope Foraging problem have hundreds of weights, meaning that the fitness landscape has just as many dimensions and is consequently very difficult to visualise.
Reducing the dimensionality of the problem to two or three dimensions makes visualisation possible and gives many valuable insights into the features of the landscape, especially if combined with a specialisation metric.
How far apart are specialist and generalist solutions in the landscape?
How many optima are there?
What trajectory does evolution take through the landscape?
There are many techniques to choose from \cite{veerapen:GPEM:2018} and further consideration is necessary before choosing one, but Sammon mapping \cite{sammon:IEEETR:1969} is currently the preferred method due to its ability to preserve the relative distances between solutions and its use in other agent-based and neuroevolution studies \cite{kim:GECCO:2003, risi:AB:2010}.

The hypothesis is:\\

\textbf{Hypothesis 1.3:} There are two optima in the landscape, one composed of specialist solutions and one composed of mostly generalist solutions. \\

\textbf{Experiment 1.3- Dimensionality Reduction:} Assemble a dataset of solutions, combining some random ones from rwg and some evolved ones.
Apply the chosen dimensionality reduction technique to the dataset.
Use the chosen specialisation metric to plot the degree of specialisation (in addition to the fitness).\\

If there are indeed two optima, then the hypothesis is supported, otherwise it is not supported.
If, additionally, the specialist solutions are fitter than the generalist ones, Hypothesis 1.2 is further supported.\\

\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{sammon.png}
\caption{Sammon Mapping of Landscape}
\label{fig:sammon}
\end{figure}

The algorithm I use to perform dimensionality reduction creates an initial 2D mapping of the genomes and calculates the error of that mapping using Sammon's error function. 
It then uses iterative gradient descent to minimise the error. 
The plot in Figure \ref{fig:sammon} includes the best 500 and worst 500 genomes from the rwg analysis in Figure \ref{fig:sparse} along with the best evolved team genomes and the best evolved individual genomes. 
For the individual genomes, I concatenated two identical copies and doubled their score so that I can put them in the same landscape.\\

Preliminary results show that there indeed appear to be two optima, which supports Hypothesis 1.3.
One of the optima has a higher score while the other has a lower score.
Anecdotally, the scores observed for the green optima are usually only seen for teams of specialists, however a specialisation metric is still needed to verify this empirically.\\

\subsection{Analysis of Different Slope Angles}

\textbf{Hypothesis 1.4.1:} When the slope is flat, there will only be one optima of generalists and no specialist solutions.\\

\textbf{Hypothesis 1.4.2:} An intermediate slope will have two optima (one specialist and one generalist).\\

\textbf{Hypothesis 1.4.3:} The specialist solutions will outscore the generalists, but the disparity will be smaller than the steeper slope setting. \\

\textbf{Experiment 1.4- RWG with Different Slope Angles:} Repeat RWG, as it was done for previous experiments, but with no slope and intermediate slope.
Then perform 30 evolutionary runs, each with a different seed genome and random seed.
Use the generated data to create RWG analysis plots and perform dimensionality reduction.\\

\subsection{Decentralised Solutions} 

\textbf{Hypothesis 1.5:} Solutions found by the decentralised algorithm will be primarily generalist whereas solutions found by the centralised algorithm will be primarily specialist.\\

\textbf{Experiment 1.5- Decentralised Dimensionality Reduction:} Perform 30 evolutionary runs of the decentralised setup.
Calculate the degree of specialisation of all evolved solutions.
Concatenate the genomes of all individuals on a team and apply dimensionality reduction to the data.
Combine the decentralised data with the centralised data and plot on the same plot.\\

\section{Centralised vs Decentralised Solutions}

\textbf{When do centralised and decentralised solutions outperform one another in task specialisation problems?}\\

\subsection{Scalability}

\textbf{Hypothesis 2.1.1:} If evolution is run with larger team sizes, the fitness of centralised solutions will decrease.\\

\textbf{Hypothesis 2.1.2:} If evolution is run with larger team sizes, the fitness of decentralised solutions will decrease less rapidly than centralised solutions\\

\textbf{Hypothesis 2.1.3} If evolution is run with larger team sizes, the centralised approach will find fewer specialists.\\

\textbf{Hypothesis 2.1.4} If evolution is run with larger team sizes, the decentralised approach will find the same number of specialists.\\

\textbf{Experiment 2.1- Evolution with Larger Teams:} Do 30 evolutionary runs (centralised and decentralised) for teams of 4, 6, 8 and 10 agents.
Calculate the specialisation of all evolved solutions.
Plot the average fitness per agent and team specialisation for teams in each setup. \\

\subsection{Robustness}

\textbf{Hypothesis 2.2.1:} When evolved teams have team-members replaced, the average fitness per agent decreases for centralised teams.\\

\textbf{Hypothesis 2.2.2:} When evolved teams have team-members replaced, the average fitness per agent decreases for decentralised teams, but by a smaller margin than centralised teams.\\

\textbf{Hypothesis 2.2.3:} When evolved teams have team-members replaced, the team specialisation decreases for centralised teams.\\

\textbf{Hypothesis 2.2.4:} When evolved teams have team-members replaced, the team specialisation remains the same for decentralised teams.\\

\textbf{Experiment 2.2- Changing Team-mates:} Take all 60 evolved 2-agent teams (30 centralised + 30 decentralised).
For each evolved team, replace one agent 4 times: once with a dropper, once with a collector, once with a generalist and once with a stationary agent.
Calculate the average fitness and team specialisation then repeat for the other agent on the team.
That is a total of $2 \times 30 \times 4 \times 2= 480 \mbox{ fitness evaluations}$. 
Create a violin plot for the centralised setup and one for decentralised setup.
Draw one violin for the original team and one for each replacement (a total of five).
The data for each violin includes when each of the two agents was replaced.
The y-axis shows the fitness and the plots also have a colour scale to show the degree of specialisation.\\

\section{Theoretical Modelling}

\textbf{What is the price of anarchy in task specialisation problems?}\\

\textbf{Hypothesis 3.1.1:} The slope foraging problem is a stag hunt with two Nash equilibria, where the payoff-dominant equilibrium is specialist solutions and the risk-dominant is generalist solutions.\\

\textbf{Hypothesis 3.1.2:} Socially optimal teams are more likely to converge to the payoff-dominant Nash equilibrum while the self-interested teams are more likely to converge to the risk-dominant Nash equilibrium.\\

\textbf{Experiment 3.1- Game-theoretic Modelling:} Formulate a game that models the experimental setup. 
Find the nash equilibria and study the learning dynamics.\\

\bibliographystyle{ieeetr}
\bibliography{references}

\appendix

\section{Summary of Results}

\begin{description}
\item[1] \textbf{What are the fundamental features of the fitness landscape of a task specialisation problem?}\\

\textbf{Answer 1.1:} Rewarding agents for partial retrieval of the resource creates a smoother fitness gradient, but the landscape is still largely flat.\\

\item[2] \textbf{When do centralised and decentralised solutions outperform one another in task specialisation problems?}\\



\item[3] \textbf{What is the price of anarchy in task specialisation problems?}\\



\end{description}

\end{document}